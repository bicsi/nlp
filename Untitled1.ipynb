{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVR, SVC\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "import tensorflow.keras.layers as tfkl\n",
    "import gensim\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df(filename, names):\n",
    "    df = pd.read_csv(filename, sep='\\t', header=None, names=names)\n",
    "    df[\"s_sub_token_len\"] = [len(s.split()) for s in df[\"sub\"]]\n",
    "    df[\"s_sub_char_len\"] = [len(s) for s in df[\"sub\"]]\n",
    "    df[\"s_capitalized\"] = [1 if s[0].isupper() else 0 for s in df[\"sub\"]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>l</th>\n",
       "      <th>r</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>p</th>\n",
       "      <th>s_sub_token_len</th>\n",
       "      <th>s_sub_char_len</th>\n",
       "      <th>s_capitalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14002.00000</td>\n",
       "      <td>14002.000000</td>\n",
       "      <td>14002.000000</td>\n",
       "      <td>14002.0</td>\n",
       "      <td>14002.0</td>\n",
       "      <td>14002.000000</td>\n",
       "      <td>14002.000000</td>\n",
       "      <td>14002.000000</td>\n",
       "      <td>14002.000000</td>\n",
       "      <td>14002.000000</td>\n",
       "      <td>14002.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7001.50000</td>\n",
       "      <td>83.727753</td>\n",
       "      <td>92.100486</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.902014</td>\n",
       "      <td>0.860591</td>\n",
       "      <td>0.088130</td>\n",
       "      <td>1.220968</td>\n",
       "      <td>8.372732</td>\n",
       "      <td>0.236323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4042.17357</td>\n",
       "      <td>66.602408</td>\n",
       "      <td>66.819266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.949611</td>\n",
       "      <td>1.894848</td>\n",
       "      <td>0.181183</td>\n",
       "      <td>0.630302</td>\n",
       "      <td>5.086451</td>\n",
       "      <td>0.424838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3501.25000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7001.50000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10501.75000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14002.00000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>656.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               idx             l             r       n1       n2  \\\n",
       "count  14002.00000  14002.000000  14002.000000  14002.0  14002.0   \n",
       "mean    7001.50000     83.727753     92.100486     10.0     10.0   \n",
       "std     4042.17357     66.602408     66.819266      0.0      0.0   \n",
       "min        1.00000      0.000000      2.000000     10.0     10.0   \n",
       "25%     3501.25000     32.000000     40.000000     10.0     10.0   \n",
       "50%     7001.50000     71.000000     79.000000     10.0     10.0   \n",
       "75%    10501.75000    120.000000    129.000000     10.0     10.0   \n",
       "max    14002.00000    647.000000    656.000000     10.0     10.0   \n",
       "\n",
       "                 c1            c2             p  s_sub_token_len  \\\n",
       "count  14002.000000  14002.000000  14002.000000     14002.000000   \n",
       "mean       0.902014      0.860591      0.088130         1.220968   \n",
       "std        1.949611      1.894848      0.181183         0.630302   \n",
       "min        0.000000      0.000000      0.000000         1.000000   \n",
       "25%        0.000000      0.000000      0.000000         1.000000   \n",
       "50%        0.000000      0.000000      0.000000         1.000000   \n",
       "75%        1.000000      1.000000      0.100000         1.000000   \n",
       "max       10.000000     10.000000      1.000000        11.000000   \n",
       "\n",
       "       s_sub_char_len  s_capitalized  \n",
       "count    14002.000000   14002.000000  \n",
       "mean         8.372732       0.236323  \n",
       "std          5.086451       0.424838  \n",
       "min          2.000000       0.000000  \n",
       "25%          5.000000       0.000000  \n",
       "50%          7.000000       0.000000  \n",
       "75%          9.000000       0.000000  \n",
       "max         49.000000       1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COL_NAMES = [\"idx\", \"text\", \"l\", \"r\", \"sub\", \"n1\", \"n2\", \"c1\", \"c2\", \"p\"]\n",
    "train_df = read_df('data/train_full.txt', COL_NAMES)\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>l</th>\n",
       "      <th>r</th>\n",
       "      <th>sub</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>p</th>\n",
       "      <th>s_sub_token_len</th>\n",
       "      <th>s_sub_char_len</th>\n",
       "      <th>s_capitalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5287</th>\n",
       "      <td>5288</td>\n",
       "      <td>Sunni gunmen stand in the middle of Syria Stre...</td>\n",
       "      <td>99</td>\n",
       "      <td>107</td>\n",
       "      <td>northern</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7515</th>\n",
       "      <td>7516</td>\n",
       "      <td>The shooting happened at a house in Port St. J...</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>John</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>1291</td>\n",
       "      <td>Unless she left a note somewhere or told someb...</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>told</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5667</th>\n",
       "      <td>5668</td>\n",
       "      <td>Mladic reportedly gave a thumbs-up and clapped...</td>\n",
       "      <td>68</td>\n",
       "      <td>73</td>\n",
       "      <td>court</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3585</th>\n",
       "      <td>3586</td>\n",
       "      <td>Manila and Beijing contest sovereignty over th...</td>\n",
       "      <td>27</td>\n",
       "      <td>38</td>\n",
       "      <td>sovereignty</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6647</th>\n",
       "      <td>6648</td>\n",
       "      <td>You don’t need to sign agreements, you need to...</td>\n",
       "      <td>104</td>\n",
       "      <td>111</td>\n",
       "      <td>Mujahid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7003</th>\n",
       "      <td>7004</td>\n",
       "      <td>The Philippine Department of Foreign Affairs s...</td>\n",
       "      <td>103</td>\n",
       "      <td>110</td>\n",
       "      <td>sighted</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13894</th>\n",
       "      <td>13895</td>\n",
       "      <td>Successive waves of bank sector clean-ups have...</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>sector</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10129</th>\n",
       "      <td>10130</td>\n",
       "      <td>Ben-Dor said that Levanon's recently named suc...</td>\n",
       "      <td>76</td>\n",
       "      <td>81</td>\n",
       "      <td>leave</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9175</th>\n",
       "      <td>9176</td>\n",
       "      <td>The Afghan people will understand that the Uni...</td>\n",
       "      <td>126</td>\n",
       "      <td>139</td>\n",
       "      <td>signing table</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13461</th>\n",
       "      <td>13462</td>\n",
       "      <td>I don't know what could have happened in the p...</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>past</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10758</th>\n",
       "      <td>10759</td>\n",
       "      <td>On Tuesday, Filipino sailors from the warship ...</td>\n",
       "      <td>66</td>\n",
       "      <td>73</td>\n",
       "      <td>vessels</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5081</th>\n",
       "      <td>5082</td>\n",
       "      <td>He made his getaway in a car that was later fo...</td>\n",
       "      <td>44</td>\n",
       "      <td>49</td>\n",
       "      <td>found</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6442</th>\n",
       "      <td>6443</td>\n",
       "      <td>A neighbor heard shots at 4:50 a.m. and then r...</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>responded to a knock</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13444</th>\n",
       "      <td>13445</td>\n",
       "      <td>The Philippine government said Wednesday it ag...</td>\n",
       "      <td>225</td>\n",
       "      <td>238</td>\n",
       "      <td>confrontation</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>719</td>\n",
       "      <td>Dozens more were wounded in Monday's violence,...</td>\n",
       "      <td>67</td>\n",
       "      <td>78</td>\n",
       "      <td>Observatory</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11847</th>\n",
       "      <td>11848</td>\n",
       "      <td>He also dismissed allegations of corruption am...</td>\n",
       "      <td>33</td>\n",
       "      <td>43</td>\n",
       "      <td>corruption</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73</td>\n",
       "      <td>The standoff began Sunday when a Philippine na...</td>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "      <td>navy</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11094</th>\n",
       "      <td>11095</td>\n",
       "      <td>But America's Kabul ambassador, Ryan Crocker, ...</td>\n",
       "      <td>174</td>\n",
       "      <td>180</td>\n",
       "      <td>blames</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12312</th>\n",
       "      <td>12313</td>\n",
       "      <td>But the violence that erupted about 90 minutes...</td>\n",
       "      <td>257</td>\n",
       "      <td>263</td>\n",
       "      <td>decade</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6443</th>\n",
       "      <td>6444</td>\n",
       "      <td>A neighbor heard shots at 4:50 a.m. and then r...</td>\n",
       "      <td>60</td>\n",
       "      <td>65</td>\n",
       "      <td>knock</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4377</th>\n",
       "      <td>4378</td>\n",
       "      <td>Opposition parties and international observers...</td>\n",
       "      <td>61</td>\n",
       "      <td>71</td>\n",
       "      <td>was marred</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>915</td>\n",
       "      <td>Unlike the police, Interior Ministry troops ar...</td>\n",
       "      <td>64</td>\n",
       "      <td>71</td>\n",
       "      <td>largely</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13055</th>\n",
       "      <td>13056</td>\n",
       "      <td>An EU statement issued at a meeting of ministe...</td>\n",
       "      <td>59</td>\n",
       "      <td>66</td>\n",
       "      <td>adopted</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>1737</td>\n",
       "      <td>The ships placed themselves between the Gregor...</td>\n",
       "      <td>75</td>\n",
       "      <td>82</td>\n",
       "      <td>vessels</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9690</th>\n",
       "      <td>9691</td>\n",
       "      <td>Afghan officials and eyewitnesses say a suicid...</td>\n",
       "      <td>74</td>\n",
       "      <td>83</td>\n",
       "      <td>disguised</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6687</th>\n",
       "      <td>6688</td>\n",
       "      <td>He didn't see the text until he woke up this m...</td>\n",
       "      <td>32</td>\n",
       "      <td>36</td>\n",
       "      <td>woke</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6199</th>\n",
       "      <td>6200</td>\n",
       "      <td>The gunman fled in a silver saloon car that wa...</td>\n",
       "      <td>21</td>\n",
       "      <td>38</td>\n",
       "      <td>silver saloon car</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12007</th>\n",
       "      <td>12008</td>\n",
       "      <td>It approved measures forcing banks to set asid...</td>\n",
       "      <td>59</td>\n",
       "      <td>63</td>\n",
       "      <td>euro</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12116</th>\n",
       "      <td>12117</td>\n",
       "      <td>On Facebook, more than 12,000 people signed up...</td>\n",
       "      <td>145</td>\n",
       "      <td>154</td>\n",
       "      <td>political</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10440</th>\n",
       "      <td>10441</td>\n",
       "      <td>The news came a day after thousands of Russian...</td>\n",
       "      <td>104</td>\n",
       "      <td>110</td>\n",
       "      <td>police</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3238</th>\n",
       "      <td>3239</td>\n",
       "      <td>A man and woman, both aged 28, arrested on sus...</td>\n",
       "      <td>83</td>\n",
       "      <td>91</td>\n",
       "      <td>released</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13819</th>\n",
       "      <td>13820</td>\n",
       "      <td>I don't know what could have happened in the p...</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>past</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12836</th>\n",
       "      <td>12837</td>\n",
       "      <td>The backdrop of armored troop carriers matched...</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>fit</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3991</th>\n",
       "      <td>3992</td>\n",
       "      <td>Deputies said that the father of the children,...</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>children</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2422</th>\n",
       "      <td>2423</td>\n",
       "      <td>The Embassy is still engaged in discussions wi...</td>\n",
       "      <td>136</td>\n",
       "      <td>145</td>\n",
       "      <td>relations</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10362</th>\n",
       "      <td>10363</td>\n",
       "      <td>The Spanish government unveiled a new reform p...</td>\n",
       "      <td>88</td>\n",
       "      <td>101</td>\n",
       "      <td>desperate bid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4750</th>\n",
       "      <td>4751</td>\n",
       "      <td>A definitive clean-up of troubled banks, as we...</td>\n",
       "      <td>209</td>\n",
       "      <td>230</td>\n",
       "      <td>tough deficit targets</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10473</th>\n",
       "      <td>10474</td>\n",
       "      <td>Therefore I think they can only take one decis...</td>\n",
       "      <td>90</td>\n",
       "      <td>94</td>\n",
       "      <td>hold</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955</th>\n",
       "      <td>4956</td>\n",
       "      <td>The watchdog said 45 people — 25 civilians, 15...</td>\n",
       "      <td>47</td>\n",
       "      <td>55</td>\n",
       "      <td>soldiers</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>2019</td>\n",
       "      <td>A cease-fire that was supposed to begin on Apr...</td>\n",
       "      <td>83</td>\n",
       "      <td>102</td>\n",
       "      <td>throwing into doubt</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12055</th>\n",
       "      <td>12056</td>\n",
       "      <td>It's the fault of the politicians and those ma...</td>\n",
       "      <td>51</td>\n",
       "      <td>72</td>\n",
       "      <td>bad lending decisions</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6544</th>\n",
       "      <td>6545</td>\n",
       "      <td>Thousands of Russians have rallied in Moscow a...</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>Russians</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>1087</td>\n",
       "      <td>As we emerge from a decade of conflict abroad ...</td>\n",
       "      <td>134</td>\n",
       "      <td>142</td>\n",
       "      <td>backdrop</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6695</th>\n",
       "      <td>6696</td>\n",
       "      <td>Deputies identified the children as Pebbles Jo...</td>\n",
       "      <td>57</td>\n",
       "      <td>61</td>\n",
       "      <td>Jaxs</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6950</th>\n",
       "      <td>6951</td>\n",
       "      <td>Mr Del Rosario said that despite the impasse, ...</td>\n",
       "      <td>50</td>\n",
       "      <td>58</td>\n",
       "      <td>resolved</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7460</th>\n",
       "      <td>7461</td>\n",
       "      <td>The government has praised the vote as a miles...</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>opposition boycotted the polls</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10479</th>\n",
       "      <td>10480</td>\n",
       "      <td>Thousands of security forces were out in the R...</td>\n",
       "      <td>45</td>\n",
       "      <td>52</td>\n",
       "      <td>Russian</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13356</th>\n",
       "      <td>13357</td>\n",
       "      <td>He counts advertising, running, musical theate...</td>\n",
       "      <td>240</td>\n",
       "      <td>245</td>\n",
       "      <td>final</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11422</th>\n",
       "      <td>11423</td>\n",
       "      <td>It also gives Google, the worlds’ biggest make...</td>\n",
       "      <td>42</td>\n",
       "      <td>47</td>\n",
       "      <td>maker</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         idx                                               text    l    r  \\\n",
       "5287    5288  Sunni gunmen stand in the middle of Syria Stre...   99  107   \n",
       "7515    7516  The shooting happened at a house in Port St. J...   45   49   \n",
       "1290    1291  Unless she left a note somewhere or told someb...   36   40   \n",
       "5667    5668  Mladic reportedly gave a thumbs-up and clapped...   68   73   \n",
       "3585    3586  Manila and Beijing contest sovereignty over th...   27   38   \n",
       "6647    6648  You don’t need to sign agreements, you need to...  104  111   \n",
       "7003    7004  The Philippine Department of Foreign Affairs s...  103  110   \n",
       "13894  13895  Successive waves of bank sector clean-ups have...   25   31   \n",
       "10129  10130  Ben-Dor said that Levanon's recently named suc...   76   81   \n",
       "9175    9176  The Afghan people will understand that the Uni...  126  139   \n",
       "13461  13462  I don't know what could have happened in the p...   45   49   \n",
       "10758  10759  On Tuesday, Filipino sailors from the warship ...   66   73   \n",
       "5081    5082  He made his getaway in a car that was later fo...   44   49   \n",
       "6442    6443  A neighbor heard shots at 4:50 a.m. and then r...   45   65   \n",
       "13444  13445  The Philippine government said Wednesday it ag...  225  238   \n",
       "718      719  Dozens more were wounded in Monday's violence,...   67   78   \n",
       "11847  11848  He also dismissed allegations of corruption am...   33   43   \n",
       "72        73  The standoff began Sunday when a Philippine na...   44   48   \n",
       "11094  11095  But America's Kabul ambassador, Ryan Crocker, ...  174  180   \n",
       "12312  12313  But the violence that erupted about 90 minutes...  257  263   \n",
       "6443    6444  A neighbor heard shots at 4:50 a.m. and then r...   60   65   \n",
       "4377    4378  Opposition parties and international observers...   61   71   \n",
       "914      915  Unlike the police, Interior Ministry troops ar...   64   71   \n",
       "13055  13056  An EU statement issued at a meeting of ministe...   59   66   \n",
       "1736    1737  The ships placed themselves between the Gregor...   75   82   \n",
       "9690    9691  Afghan officials and eyewitnesses say a suicid...   74   83   \n",
       "6687    6688  He didn't see the text until he woke up this m...   32   36   \n",
       "6199    6200  The gunman fled in a silver saloon car that wa...   21   38   \n",
       "12007  12008  It approved measures forcing banks to set asid...   59   63   \n",
       "12116  12117  On Facebook, more than 12,000 people signed up...  145  154   \n",
       "10440  10441  The news came a day after thousands of Russian...  104  110   \n",
       "3238    3239  A man and woman, both aged 28, arrested on sus...   83   91   \n",
       "13819  13820  I don't know what could have happened in the p...   45   49   \n",
       "12836  12837  The backdrop of armored troop carriers matched...  143  146   \n",
       "3991    3992  Deputies said that the father of the children,...   37   45   \n",
       "2422    2423  The Embassy is still engaged in discussions wi...  136  145   \n",
       "10362  10363  The Spanish government unveiled a new reform p...   88  101   \n",
       "4750    4751  A definitive clean-up of troubled banks, as we...  209  230   \n",
       "10473  10474  Therefore I think they can only take one decis...   90   94   \n",
       "4955    4956  The watchdog said 45 people — 25 civilians, 15...   47   55   \n",
       "2018    2019  A cease-fire that was supposed to begin on Apr...   83  102   \n",
       "12055  12056  It's the fault of the politicians and those ma...   51   72   \n",
       "6544    6545  Thousands of Russians have rallied in Moscow a...   13   21   \n",
       "1086    1087  As we emerge from a decade of conflict abroad ...  134  142   \n",
       "6695    6696  Deputies identified the children as Pebbles Jo...   57   61   \n",
       "6950    6951  Mr Del Rosario said that despite the impasse, ...   50   58   \n",
       "7460    7461  The government has praised the vote as a miles...   90  120   \n",
       "10479  10480  Thousands of security forces were out in the R...   45   52   \n",
       "13356  13357  He counts advertising, running, musical theate...  240  245   \n",
       "11422  11423  It also gives Google, the worlds’ biggest make...   42   47   \n",
       "\n",
       "                                  sub  n1  n2  c1  c2     p  s_sub_token_len  \\\n",
       "5287                         northern  10  10   0   0  0.00                1   \n",
       "7515                             John  10  10   0   0  0.00                1   \n",
       "1290                             told  10  10   0   0  0.00                1   \n",
       "5667                            court  10  10   0   0  0.00                1   \n",
       "3585                      sovereignty  10  10   8   8  0.80                1   \n",
       "6647                          Mujahid  10  10   0   0  0.00                1   \n",
       "7003                          sighted  10  10   1   2  0.15                1   \n",
       "13894                          sector  10  10   1   0  0.05                1   \n",
       "10129                           leave  10  10   0   0  0.00                1   \n",
       "9175                    signing table  10  10   0   0  0.00                2   \n",
       "13461                            past  10  10   0   0  0.00                1   \n",
       "10758                         vessels  10  10   1   1  0.10                1   \n",
       "5081                            found  10  10   0   0  0.00                1   \n",
       "6442             responded to a knock  10  10   0   1  0.05                4   \n",
       "13444                   confrontation  10  10  10   8  0.90                1   \n",
       "718                       Observatory  10  10   1   5  0.30                1   \n",
       "11847                      corruption  10  10   7   4  0.55                1   \n",
       "72                               navy  10  10   0   0  0.00                1   \n",
       "11094                          blames  10  10   1   2  0.15                1   \n",
       "12312                          decade  10  10   2   6  0.40                1   \n",
       "6443                            knock  10  10   0   1  0.05                1   \n",
       "4377                       was marred  10  10   0   1  0.05                2   \n",
       "914                           largely  10  10   0   0  0.00                1   \n",
       "13055                         adopted  10  10   2   1  0.15                1   \n",
       "1736                          vessels  10  10   4   0  0.20                1   \n",
       "9690                        disguised  10  10   1   7  0.40                1   \n",
       "6687                             woke  10  10   0   0  0.00                1   \n",
       "6199                silver saloon car  10  10   0   1  0.05                3   \n",
       "12007                            euro  10  10   0   0  0.00                1   \n",
       "12116                       political  10  10   0   0  0.00                1   \n",
       "10440                          police  10  10   0   0  0.00                1   \n",
       "3238                         released  10  10   1   1  0.10                1   \n",
       "13819                            past  10  10   0   0  0.00                1   \n",
       "12836                             fit  10  10   1   0  0.05                1   \n",
       "3991                         children  10  10   0   0  0.00                1   \n",
       "2422                        relations  10  10   3   0  0.15                1   \n",
       "10362                   desperate bid  10  10   2   0  0.10                2   \n",
       "4750            tough deficit targets  10  10   1   1  0.10                3   \n",
       "10473                            hold  10  10   0   0  0.00                1   \n",
       "4955                         soldiers  10  10   0   0  0.00                1   \n",
       "2018              throwing into doubt  10  10   1   1  0.10                3   \n",
       "12055           bad lending decisions  10  10   1   1  0.10                3   \n",
       "6544                         Russians  10  10   0   0  0.00                1   \n",
       "1086                         backdrop  10  10   6   8  0.70                1   \n",
       "6695                             Jaxs  10  10   0   0  0.00                1   \n",
       "6950                         resolved  10  10   0   2  0.10                1   \n",
       "7460   opposition boycotted the polls  10  10   0   0  0.00                4   \n",
       "10479                         Russian  10  10   0   0  0.00                1   \n",
       "13356                           final  10  10   0   0  0.00                1   \n",
       "11422                           maker  10  10   0   0  0.00                1   \n",
       "\n",
       "       s_sub_char_len  s_capitalized  \n",
       "5287                8              0  \n",
       "7515                4              1  \n",
       "1290                4              0  \n",
       "5667                5              0  \n",
       "3585               11              0  \n",
       "6647                7              1  \n",
       "7003                7              0  \n",
       "13894               6              0  \n",
       "10129               5              0  \n",
       "9175               13              0  \n",
       "13461               4              0  \n",
       "10758               7              0  \n",
       "5081                5              0  \n",
       "6442               20              0  \n",
       "13444              13              0  \n",
       "718                11              1  \n",
       "11847              10              0  \n",
       "72                  4              0  \n",
       "11094               6              0  \n",
       "12312               6              0  \n",
       "6443                5              0  \n",
       "4377               10              0  \n",
       "914                 7              0  \n",
       "13055               7              0  \n",
       "1736                7              0  \n",
       "9690                9              0  \n",
       "6687                4              0  \n",
       "6199               17              0  \n",
       "12007               4              0  \n",
       "12116               9              0  \n",
       "10440               6              0  \n",
       "3238                8              0  \n",
       "13819               4              0  \n",
       "12836               3              0  \n",
       "3991                8              0  \n",
       "2422                9              0  \n",
       "10362              13              0  \n",
       "4750               21              0  \n",
       "10473               4              0  \n",
       "4955                8              0  \n",
       "2018               19              0  \n",
       "12055              21              0  \n",
       "6544                8              1  \n",
       "1086                8              0  \n",
       "6695                4              1  \n",
       "6950                8              0  \n",
       "7460               30              0  \n",
       "10479               7              1  \n",
       "13356               5              0  \n",
       "11422               5              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model!\n"
     ]
    }
   ],
   "source": [
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "    './GoogleNews-vectors-negative300.bin', binary=True) \n",
    "print(\"Loaded model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_TAG_CACHE = {}\n",
    "\n",
    "def pos_tag(text):\n",
    "    global POS_TAG_CACHE\n",
    "    if text not in POS_TAG_CACHE:\n",
    "        POS_TAG_CACHE[text] = nltk.pos_tag(\n",
    "            nltk.word_tokenize(text),\n",
    "            # tagset='universal',\n",
    "        )\n",
    "    return POS_TAG_CACHE[text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['', 'CC', 'CD', 'DT', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'MD', 'NN',\n",
      "       'NNP', 'NNPS', 'NNS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP',\n",
      "       'TO', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WP'], dtype='<U4')]\n",
      "[ 1.00000000e+00  3.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -3.59690910e-16 -1.16335119e-16]\n",
      "(14002, 6)\n"
     ]
    }
   ],
   "source": [
    "def get_syn(df, data, include_pos=True, testing=False):\n",
    "    cols = []\n",
    "    for col in df.columns:\n",
    "        if col.startswith(\"s_\"):\n",
    "            cols.append(df[col].values)\n",
    "    ret = np.column_stack(cols)\n",
    "    \n",
    "    if include_pos:\n",
    "        pos_tags = []\n",
    "        for idx in range(len(df)):\n",
    "            target = nltk.word_tokenize(df['sub'][idx])[0]\n",
    "            tag = \"\"\n",
    "            for w, t in pos_tag(df['text'][idx]):\n",
    "                if w == target:\n",
    "                    tag = t\n",
    "                    break\n",
    "            pos_tags.append(tag)\n",
    "        pos_tags = np.array(pos_tags).reshape(len(pos_tags), 1)\n",
    "        # print(pos_tags)\n",
    "        \n",
    "        if not testing:\n",
    "            enc = OneHotEncoder()\n",
    "            enc.fit(pos_tags)\n",
    "            data['syn'] = {\n",
    "                'pos_enc': enc,\n",
    "            }\n",
    "        enc = data['syn']['pos_enc']\n",
    "        print(enc.categories_)\n",
    "        \n",
    "        pos_tags_onehot = enc.transform(pos_tags)\n",
    "        \n",
    "        if not testing:\n",
    "            pca = TruncatedSVD(n_components=3)\n",
    "            pca.fit(pos_tags_onehot.toarray())\n",
    "            data[\"syn\"][\"pos_pca\"] = pca\n",
    "        pca = data[\"syn\"][\"pos_pca\"]\n",
    "        \n",
    "        pos_tags_enc = pca.transform(pos_tags_onehot.toarray())\n",
    "        # pos_tags_enc = pos_tags_onehot.toarray()\n",
    "\n",
    "        ret = np.hstack([ret, pos_tags_enc])\n",
    "    return ret\n",
    "\n",
    "X_syn = get_syn(train_df, DATA)\n",
    "print(X_syn[10])\n",
    "print(X_syn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping word: St\n",
      "attempt to hold an unsanctioned rally in St.\n",
      "Skipping word: St\n",
      "of Russians who rallied in Moscow and St.\n",
      "Skipping word: a.m\n",
      "murders happened around 4:30 a.m.\n",
      "Skipping word: Mr\n",
      "former President Bill Clinton touted Mr.\n",
      "Skipping word: a.m\n",
      "neighbor heard shots at 4:50 a.m.\n",
      "Skipping word: a.m\n",
      "a text from Thomas at about 3 a.m.\n",
      "Skipping word: St\n",
      "of Russians have rallied in Moscow and St.\n",
      "Skipping word: Co\n",
      "companies such as Samsung Electronics Co.\n",
      "Skipping word: Mr\n",
      "arriving, about midnight local time, Mr.\n",
      "Skipping word: St\n",
      "of Russians rallied in Moscow and St.\n",
      "Skipping word: a.m\n",
      "home to mostly foreigners at about 6:15 a.m.\n",
      "Skipping word: a.m\n",
      "been hitting the town since three a.m.\n",
      "Skipping word: said\n",
      "that killed Osama bin Laden,'' he said.\n",
      "Skipping word: .\n",
      "that killed Osama bin Laden,'' he said.\n",
      "Skipping word: said\n",
      "killed Osama bin Laden,'' he said.\n",
      "Skipping word: .\n",
      "killed Osama bin Laden,'' he said.\n",
      "Skipping word: Ms\n",
      "reported having heard gun shots from Ms.\n",
      "Skipping word: Ms\n",
      "having heard gun shots from Ms.\n",
      "Skipping word: Ms\n",
      "she opened the door, three of Ms.\n",
      "Skipping word: a.m\n",
      "message to her neighbor around 3 a.m.\n",
      "[-6.03027344e-02  1.09863281e-01 -2.37792969e-01  1.40563965e-01\n",
      "  4.36172485e-02 -1.46850586e-01 -2.09228516e-01 -2.19238281e-01\n",
      " -4.39453125e-02  3.95019531e-01 -4.00390625e-02 -1.77978516e-01\n",
      "  5.56640625e-02 -4.00390625e-02 -4.98046875e-02  5.18188477e-02\n",
      " -3.39843750e-01  3.44482422e-01 -2.87597656e-01 -1.07421875e-02\n",
      " -4.06738281e-01 -2.03613281e-01  1.58691406e-03 -1.87744141e-01\n",
      "  5.61523438e-03 -2.08496094e-01 -2.06481934e-01 -7.66601562e-02\n",
      "  3.80859375e-02 -3.01757812e-01 -1.22558594e-01  1.27197266e-01\n",
      "  1.15234375e-01 -1.64062500e-01 -1.88476562e-01 -1.89453125e-01\n",
      "  1.38732910e-01 -8.53881836e-02  3.90625000e-02 -1.30737305e-01\n",
      " -1.02050781e-01  1.18896484e-01  6.49414062e-02  1.63574219e-01\n",
      "  8.88671875e-02 -3.39843750e-01 -1.59790039e-01 -2.16796875e-01\n",
      "  2.77099609e-02 -1.04980469e-01  1.36230469e-01 -2.87597656e-01\n",
      "  2.46582031e-01  1.15722656e-01  1.47460938e-01  3.29101562e-01\n",
      " -6.78710938e-02 -2.85644531e-02 -5.44433594e-02  5.73730469e-03\n",
      " -2.91503906e-01 -2.02148438e-01  1.70410156e-01 -1.86523438e-01\n",
      " -1.74621582e-01  4.46472168e-02 -1.79687500e-01 -1.78466797e-01\n",
      "  2.67578125e-01 -5.10253906e-02 -2.55859375e-01 -2.76367188e-01\n",
      "  1.40014648e-01 -2.63183594e-01 -3.51074219e-01 -2.28027344e-01\n",
      "  1.16699219e-01 -1.90185547e-01 -1.18347168e-01 -1.85546875e-02\n",
      "  5.49316406e-02  4.07714844e-02 -1.52832031e-01 -4.25781250e-01\n",
      "  9.93652344e-02  1.43737793e-02  1.38183594e-01 -4.78515625e-02\n",
      " -6.59179688e-02  1.07910156e-01 -1.79443359e-01 -2.09472656e-01\n",
      " -2.31933594e-01  3.72070312e-01  2.11423874e-01  2.54364014e-02\n",
      "  2.39746094e-01 -1.29150391e-01  2.86132812e-01 -1.83227539e-01\n",
      " -8.12988281e-02 -1.90185547e-01 -1.42089844e-01 -2.22167969e-02\n",
      " -1.96777344e-01 -1.78710938e-01  2.13134766e-01  8.89892578e-02\n",
      "  6.05468750e-02  1.76269531e-01 -4.35058594e-01 -1.67907715e-01\n",
      "  3.81347656e-01  5.76171875e-02  2.35595703e-01  1.66015625e-02\n",
      "  2.29248047e-01 -1.73095703e-01  6.87255859e-02  5.85937500e-03\n",
      " -1.80175781e-01  2.49511719e-01  1.23962402e-01  1.43554688e-01\n",
      "  6.36444092e-02 -2.57453918e-02  1.07421875e-02  1.49169922e-01\n",
      " -2.53906250e-01 -2.34375000e-02 -2.29492188e-01 -8.59375000e-02\n",
      "  1.19262695e-01  4.27734375e-01 -1.71386719e-01 -5.49926758e-02\n",
      " -1.84402466e-01 -3.14819336e-01  5.34667969e-02  5.39672852e-01\n",
      " -1.81396484e-01 -2.56835938e-01  5.72509766e-02  4.39453125e-01\n",
      "  2.13378906e-01  1.50146484e-01  4.88281250e-03  2.43652344e-01\n",
      " -3.12500000e-01 -1.76269531e-01  4.10156250e-02 -2.57324219e-01\n",
      " -3.85742188e-01  1.16210938e-01  2.37792969e-01  1.55273438e-01\n",
      "  8.20617676e-02 -2.99804688e-01  1.10107422e-01  2.81738281e-01\n",
      "  2.82226562e-01  3.25683594e-01  3.02246094e-01  1.33056641e-01\n",
      " -1.59423828e-01 -7.93457031e-02 -1.46484375e-02 -2.08007812e-01\n",
      " -2.64160156e-01  1.48925781e-01  1.52587891e-01  3.29101562e-01\n",
      "  5.71289062e-02  2.70019531e-01 -8.74938965e-02  1.35742188e-01\n",
      "  2.94799805e-02 -1.83105469e-02  6.04248047e-02 -4.12597656e-02\n",
      " -3.75976562e-01 -1.97830200e-01 -9.64355469e-02  1.11633301e-01\n",
      " -7.54547119e-02  1.18568420e-01  4.65087891e-02  3.10058594e-02\n",
      "  9.83886719e-02 -1.22802734e-01 -9.25292969e-02 -3.09570312e-01\n",
      " -1.37443542e-01  1.09130859e-01  3.89404297e-02  3.25195312e-01\n",
      "  5.14648438e-01 -9.26513672e-02  2.84667969e-01 -1.66503906e-01\n",
      "  2.62695312e-01 -9.83886719e-02 -2.84179688e-01 -5.72509766e-02\n",
      "  7.16552734e-02  2.81494141e-01  1.63574219e-01  3.07617188e-02\n",
      " -7.52563477e-02 -4.99267578e-02 -1.65222168e-01  1.07421875e-02\n",
      " -1.03637695e-01  1.53808594e-01  1.04003906e-01  2.41699219e-01\n",
      "  4.24919128e-02 -1.95800781e-01  2.85156250e-01  5.85937500e-02\n",
      "  2.75878906e-01  7.19528198e-02 -8.36181641e-02  2.91748047e-01\n",
      " -9.99755859e-02  1.18164062e-01  5.87615967e-02  2.06542969e-01\n",
      "  3.32031250e-01  7.58666992e-02 -3.29589844e-02 -1.23535156e-01\n",
      " -1.55090332e-01 -2.00195312e-02 -1.71142578e-01 -5.76171875e-02\n",
      "  9.84649658e-02  1.74316406e-01  3.88671875e-01  2.08007812e-01\n",
      "  2.49511719e-01 -3.03710938e-01  3.02734375e-02 -1.67724609e-01\n",
      " -2.20214844e-01  9.39941406e-02 -7.22656250e-02  1.61132812e-01\n",
      " -1.07421875e-02  8.76464844e-02 -8.03222656e-02 -3.37890625e-01\n",
      "  2.92968750e-02 -2.44140625e-03  1.23046875e-01 -3.57421875e-01\n",
      " -7.56835938e-03 -7.83691406e-02  1.18164062e-01  1.65039062e-01\n",
      "  2.49023438e-02 -1.67480469e-01 -1.56005859e-01 -1.36718750e-02\n",
      "  1.81640625e-01  4.19433594e-01 -3.13964844e-01  6.83593750e-03\n",
      "  2.98828125e-01 -3.42285156e-01 -5.27343750e-01  3.26171875e-01\n",
      "  7.91015625e-02  1.37390137e-01  6.11572266e-02  3.83789062e-01\n",
      "  1.36230469e-01 -2.33825684e-01  1.47705078e-01  1.01806641e-01\n",
      " -9.32617188e-02 -1.45751953e-01  4.27734375e-01 -8.94775391e-02\n",
      " -4.88281250e-04 -5.33203125e-01  8.32519531e-02  2.14843750e-02\n",
      "  2.85034180e-02  2.72949219e-01 -4.39453125e-02  2.29873657e-02\n",
      " -1.00097656e-02 -9.48486328e-02  4.02832031e-02  7.98339844e-02\n",
      " -1.36718750e-01 -1.45996094e-01  4.85351562e-01  4.15039062e-02\n",
      " -2.58061120e-03  2.83654490e-03 -2.30840566e-02  9.00747296e-03\n",
      "  9.36474726e-04 -1.07461400e-02 -3.02483442e-02 -1.61455303e-02\n",
      "  1.59046601e-02  5.38878207e-02  1.36054520e-03 -3.90231301e-02\n",
      " -7.57931848e-04 -9.45369335e-03 -8.42120738e-03  1.82320951e-02\n",
      " -4.02484913e-02  4.81880885e-02 -2.65657079e-02  2.96820732e-02\n",
      " -2.75576322e-02 -2.84931908e-02  1.90384877e-02 -1.88391094e-02\n",
      "  1.93848921e-02 -3.87030912e-02 -4.41340954e-02 -1.23378672e-02\n",
      "  1.78896890e-02 -3.68413606e-02 -1.45300937e-02  2.01939533e-02\n",
      " -5.50051326e-03 -5.38075306e-03  7.53229550e-03 -2.64100444e-02\n",
      "  4.06873522e-03 -1.38733542e-02  2.80981434e-03 -8.57817903e-03\n",
      "  1.40811184e-04  3.82835250e-02  9.21669223e-03  1.82025586e-02\n",
      "  1.81924626e-02 -5.11273943e-02 -7.27896825e-03 -2.43635142e-02\n",
      " -1.95197123e-03 -1.09733835e-02  2.68810660e-02 -3.20606289e-02\n",
      "  3.23025071e-02  3.39700480e-03  1.36292491e-02  3.69878163e-02\n",
      " -1.82949472e-02 -2.11849345e-02 -1.95558488e-03 -1.02979821e-02\n",
      " -3.24664754e-02 -1.72972709e-02  1.37702863e-02 -2.22374685e-02\n",
      " -4.69745782e-03  1.04652964e-02 -2.44267337e-02  1.00459937e-04\n",
      "  1.33738577e-02 -1.38622502e-02 -3.23071053e-02 -1.83202992e-02\n",
      "  2.83290089e-02 -1.95924617e-02 -5.55021328e-02 -4.19773196e-02\n",
      " -6.54987041e-04 -1.24125891e-02 -6.86048858e-03 -1.22399719e-02\n",
      "  9.98148695e-03 -1.85247085e-03 -1.91735559e-02 -4.64039941e-02\n",
      "  3.99033805e-03  5.28434152e-03  2.56465459e-03 -5.86973916e-03\n",
      "  1.23561665e-02  4.41726586e-03 -3.71939004e-03 -1.96308136e-02\n",
      " -2.37433544e-02  2.83711887e-02  1.86740170e-02  8.40293784e-03\n",
      "  2.24713360e-02 -2.30697033e-02  4.21549076e-02 -1.91583825e-02\n",
      "  9.80890313e-03 -6.61918654e-03  1.07542139e-03  1.04775893e-02\n",
      " -1.66921118e-02 -1.45296288e-02  2.02036276e-02  2.66857821e-03\n",
      "  2.02957115e-02  2.66707237e-02 -4.77888494e-02 -1.33540250e-02\n",
      "  5.04435647e-02  1.52063361e-02  1.82239168e-02 -1.16602991e-02\n",
      "  3.01472547e-02 -2.51741611e-02 -1.39484395e-03  6.69774553e-03\n",
      " -3.97908935e-02  2.80591713e-02  1.12144820e-02  3.01163988e-02\n",
      " -4.72117598e-03 -4.82602901e-03 -1.50719624e-03  1.25068107e-02\n",
      " -2.91715012e-02  6.94448627e-03 -3.23407073e-03 -1.43796805e-02\n",
      "  1.22715971e-02  4.01520705e-02 -1.22265945e-02 -1.30165999e-02\n",
      " -8.83739879e-03 -3.06846623e-02  1.26539682e-02  6.97399238e-02\n",
      " -2.71167160e-02 -2.86565285e-02  1.64832989e-02  5.09722096e-02\n",
      "  2.39800138e-02  2.16040187e-02 -3.29993432e-03  2.93444914e-02\n",
      " -2.97230663e-02 -1.28141275e-02  1.96612118e-02 -1.32362258e-02\n",
      " -5.92200735e-02  1.60787285e-02  2.34800324e-02  1.57326251e-02\n",
      "  1.43637714e-04 -4.54269492e-02  2.03150281e-02  3.13858852e-02\n",
      "  2.57321061e-02  4.41086532e-02  3.28389288e-02  1.00258652e-02\n",
      " -1.85821374e-02 -1.31359281e-02 -1.90866920e-02 -2.24960646e-02\n",
      " -2.54960099e-02  1.93292261e-02  4.98339960e-03  3.99890630e-02\n",
      "  7.68773487e-03  1.30705273e-02 -1.96292562e-02  6.15660110e-03\n",
      "  1.82342548e-03  1.92094323e-03 -1.20202829e-02  6.35040987e-03\n",
      " -4.77048860e-02 -3.85242816e-02 -1.83262942e-02  1.58585883e-02\n",
      " -1.01974790e-02 -7.21106071e-03 -2.69900989e-03  1.49157708e-03\n",
      "  4.59105102e-02 -5.50152075e-03 -1.83648421e-02 -3.64856192e-02\n",
      " -1.98693812e-02  6.72370255e-03 -1.01039661e-02  4.26758110e-02\n",
      "  5.68233899e-02 -4.13319236e-03  1.89807109e-02 -4.52307004e-02\n",
      "  4.51914153e-02 -1.55821164e-02 -4.50633083e-02 -7.69510658e-03\n",
      " -1.31467506e-02  3.26024860e-02  2.25937976e-02 -6.92003573e-03\n",
      " -1.15567249e-02 -4.96660020e-03 -1.41400930e-02 -2.14131975e-03\n",
      " -1.30906648e-02  3.05447242e-02  3.46944012e-03  1.27908917e-02\n",
      "  2.06173622e-02 -2.38934707e-02  3.51921951e-02  9.68607374e-03\n",
      "  4.40883537e-02 -9.30114799e-04 -2.27395796e-02  8.16112364e-03\n",
      " -9.50710675e-03  7.38583522e-04  1.46321919e-02  4.36233829e-02\n",
      "  3.23631117e-02  2.04013322e-02 -6.40598575e-03 -2.65243356e-02\n",
      " -9.64391182e-03 -1.44169766e-02  8.98014102e-03 -5.59031406e-03\n",
      "  1.61222484e-02  1.28852990e-02  4.68566084e-02  1.05407506e-02\n",
      "  3.39075792e-02 -2.66027114e-02  7.95068968e-03 -2.40853138e-02\n",
      " -1.75014492e-02  3.72053889e-03  1.02209669e-03  2.19577227e-02\n",
      "  1.80772071e-02  1.47839775e-02 -2.92396200e-02 -4.23197921e-02\n",
      "  8.37160328e-03  1.96425826e-02  6.68213799e-03 -5.21709372e-02\n",
      "  1.22748034e-02 -6.76734107e-03  1.20193392e-03  1.59413557e-02\n",
      "  1.97239460e-02 -2.93533630e-02 -1.43903841e-02  7.18744073e-03\n",
      "  7.38133540e-03  5.26367357e-02 -4.25852373e-02 -8.29213565e-03\n",
      "  2.67360370e-02 -4.17239795e-02 -5.46169324e-02  3.79765341e-02\n",
      "  1.78927596e-03  3.14621758e-02  5.90968561e-03  4.35568933e-02\n",
      " -9.43167283e-03 -2.86274823e-02  8.32376240e-03  3.50127249e-03\n",
      " -1.89204858e-02 -2.67591821e-02  5.22138319e-02 -2.16050266e-02\n",
      "  1.58509957e-02 -7.33672843e-02 -5.10424133e-03  1.22169438e-03\n",
      "  5.71918907e-03  3.38561965e-02 -5.84048974e-03 -6.76251867e-03\n",
      " -1.47135408e-02 -6.08563490e-03  5.39164295e-03  1.26188321e-02\n",
      " -3.47186409e-02 -2.76539760e-02  8.27032964e-02  3.33699305e-03]\n",
      "(14002, 600)\n"
     ]
    }
   ],
   "source": [
    "def get_emb(df, data, window_size=20, use_tfidf=True, testing=False):\n",
    "    def preprocess_text(text):\n",
    "        return nltk.word_tokenize(text)\n",
    "    \n",
    "    if not testing:\n",
    "        dataset = [preprocess_text(text) \n",
    "                   for text in np.unique(df['text'])]\n",
    "        dct = gensim.corpora.Dictionary(dataset)\n",
    "        corpus = [dct.doc2bow(line) for line in dataset]\n",
    "        tfidf = gensim.models.TfidfModel(corpus) \n",
    "        data['emb'] = {\n",
    "            \"tfidf\": tfidf,\n",
    "            \"dct\": dct,\n",
    "        }\n",
    "        \n",
    "    X_emb = np.zeros((len(df), 600))\n",
    "    for idx in range(len(df)):\n",
    "        sub = df['sub'][idx]\n",
    "        text = df['text'][idx]\n",
    "        \n",
    "        l, r = df['l'][idx], df['r'][idx]\n",
    "        text_window = text[max(0, l - window_size):(r + window_size)]\n",
    "        text_window = text_window.split(' ', 1)[1]\n",
    "        text_window = text_window.rsplit(' ', 1)[0]\n",
    "        \n",
    "        now_emb = np.zeros((300,))\n",
    "        cnt = 0\n",
    "        \n",
    "        tfidf = data['emb']['tfidf']\n",
    "        dct = data['emb']['dct']\n",
    "        \n",
    "        for token in nltk.word_tokenize(sub):\n",
    "            try:\n",
    "                emb = w2v_model[token]\n",
    "                now_emb += emb\n",
    "                cnt += 1\n",
    "            except KeyError:\n",
    "                #print(f\"{token} not found\")\n",
    "                #print(text_window)\n",
    "                pass\n",
    "        if cnt > 0:\n",
    "            now_emb /= cnt\n",
    "            \n",
    "        X_emb[idx, :300] = now_emb\n",
    "        \n",
    "        now_emb = np.zeros((300,))\n",
    "        cnt = 0\n",
    "        \n",
    "        text_coefs = dict(tfidf[dct.doc2bow(preprocess_text(text))])\n",
    "        for token in nltk.word_tokenize(text_window):\n",
    "#             if token in sub:\n",
    "#                 continue     \n",
    "            if not use_tfidf:\n",
    "                coef = 1.\n",
    "            else:\n",
    "                if token in dct.token2id:\n",
    "                    token_id = dct.token2id[token]\n",
    "                    if token_id not in text_coefs:\n",
    "                        print(f\"Skipping word: {token}\")\n",
    "                        print(text_window)\n",
    "                        continue\n",
    "                    coef = text_coefs[token_id]\n",
    "                else:\n",
    "                    continue\n",
    "            try:\n",
    "                emb = w2v_model[token]\n",
    "                now_emb += emb * coef\n",
    "                cnt += 1\n",
    "            except KeyError:\n",
    "                pass\n",
    "        if cnt > 0:\n",
    "            now_emb /= cnt\n",
    "        \n",
    "        X_emb[idx, 300:] = now_emb\n",
    "    return X_emb\n",
    "\n",
    "X_emb = get_emb(train_df, DATA)\n",
    "print(X_emb[5])\n",
    "print(X_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.20994460e-03  2.41875527e-03  1.45912071e-03  1.18640497e-03\n",
      "  6.93149702e-03  1.28309318e-02 -9.50120082e-04  3.27232859e-04\n",
      "  2.24984707e-03 -1.97380126e-04  7.22735488e-04  2.46352006e-03\n",
      "  6.13570363e-03 -1.00471580e-03  2.93746752e-02 -2.31674008e-03\n",
      "  5.45249728e-03 -2.28555090e-02  1.26885347e-02 -2.02274460e-02\n",
      " -5.75864206e-03 -5.84090412e-02  4.14391021e-02  2.16054999e-02\n",
      "  9.66581042e-03 -2.13307335e-03 -1.82379976e-03 -4.98562694e-03\n",
      "  4.37075790e-03  3.39416911e-03 -4.04889637e-03 -4.15266584e-03\n",
      "  8.87028033e-04 -4.05616019e-03 -5.01468341e-03 -2.27706021e-03\n",
      " -2.17869112e-03  4.19123843e-03  2.00424557e-03  1.05889863e-03\n",
      "  2.18452243e-03  9.61164113e-04 -4.24813612e-03  1.12775108e-03\n",
      "  4.84566365e-03  5.53398615e-03  8.86778526e-03 -6.98947963e-03\n",
      "  6.45702942e-03  9.05866736e-04 -5.68522997e-03 -4.67949041e-03\n",
      "  5.61149084e-03 -2.96899019e-03 -7.30236172e-03 -1.00448028e-03\n",
      "  3.48220088e-03 -1.35930277e-03  2.32022880e-03 -8.27001653e-03\n",
      " -5.77110950e-03  8.83283108e-04  3.43026066e-04 -6.13130578e-03\n",
      "  2.17910488e-03  4.22951712e-03 -2.37936395e-03  6.64917340e-05\n",
      " -6.25433473e-03 -7.74193343e-04  3.64558298e-04 -5.32074140e-03\n",
      " -4.15065162e-03 -2.99678377e-03 -1.05026157e-03  2.44134716e-03\n",
      "  3.05295546e-03  2.22228645e-03 -1.99488020e-03 -8.16222140e-03\n",
      " -6.34767127e-04 -1.04935890e-03 -6.58607626e-03  1.22860850e-03\n",
      " -2.54201674e-03  4.48507599e-03  7.63949335e-03 -1.25181700e-03\n",
      " -3.14241606e-03 -2.60118436e-03  2.94775097e-03 -1.27622986e-02\n",
      "  6.67379608e-03  3.65259681e-03  3.54622879e-03  3.47996634e-03\n",
      " -6.71477610e-03 -3.48492808e-03 -9.38006382e-03  7.67489600e-03]\n",
      "(14002, 100)\n"
     ]
    }
   ],
   "source": [
    "def get_grams(df, data, testing=False):\n",
    "\n",
    "    def preprocess_sub(sub):\n",
    "        sub = sub.lower()\n",
    "        tokenized = nltk.word_tokenize(sub)\n",
    "        ngrams = []\n",
    "        for token in tokenized:\n",
    "            ngrams.extend(nltk.everygrams(token, 3, 4))\n",
    "        ngrams = \" \".join([\"\".join(ngram) for ngram in ngrams])\n",
    "        return ngrams\n",
    "    \n",
    "    corpus = list(map(preprocess_sub, df[\"sub\"].values))\n",
    "    \n",
    "    if not testing:\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectorizer.fit(corpus)\n",
    "        data['grams'] = {\n",
    "            'vectorizer': vectorizer,\n",
    "        }\n",
    "    vectorizer = data['grams']['vectorizer']\n",
    "    \n",
    "    X_grams = vectorizer.transform(corpus)\n",
    "    \n",
    "    if not testing:\n",
    "        pca = TruncatedSVD(n_components=100)\n",
    "        pca.fit(X_grams)\n",
    "        data['grams'][\"pca\"] = pca\n",
    "    pca = data['grams']['pca']\n",
    "    \n",
    "    X_grams = pca.transform(X_grams)\n",
    "    \n",
    "    return X_grams\n",
    "\n",
    "X_grams = get_grams(train_df, DATA)\n",
    "print(X_grams[5])\n",
    "print(X_grams.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(X, data, testing=False):\n",
    "    if not testing:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        data[\"scaler\"] = scaler\n",
    "    scaler = data[\"scaler\"]\n",
    "    \n",
    "    return scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14002, 700)\n",
      "(14002,)\n"
     ]
    }
   ],
   "source": [
    "X = np.hstack([X_emb, X_grams])\n",
    "# X = scale(X, DATA)\n",
    "y = train_df[\"p\"].values\n",
    "# idx = (y > 0)\n",
    "# X = X[idx]\n",
    "# y = y[idx]\n",
    "# print(idx)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_loss(y_true, y_pred):\n",
    "    ret = tf.math.abs(y_true - y_pred)\n",
    "    return tf.math.maximum(ret, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(syn_dim, emb_dim, lstm_shape):\n",
    "    syn_i = tfkl.Input(shape=(syn_dim,), name='syn_i')\n",
    "    emb_i = tfkl.Input(shape=(emb_dim,), name='emb_i')\n",
    "    lstm_i = tfkl.Input(shape=lstm_shape, name='lstm_i')\n",
    "    \n",
    "    syn_o = syn_i\n",
    "    emb_o = tfkl.Dropout(0.7, name='emb_dropout')(emb_i)\n",
    "    lstm_o = tfkl.Bidirectional(tfkl.LSTM(64), name='bilstm')(lstm_i)\n",
    "    \n",
    "    x = tfkl.Concatenate()([syn_o, emb_o, lstm_o])\n",
    "    x = tfkl.Dense(300, activation='relu')(x)\n",
    "    pred = tfkl.Dense(1)(x)\n",
    "    \n",
    "    return tfk.Model([syn_i, emb_i, lstm_i], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14002, 50, 41)\n"
     ]
    }
   ],
   "source": [
    "def get_lstm_repr(df, data, training=False):\n",
    "    if not training:\n",
    "        char_enc = LabelEncoder()\n",
    "        chars = list(set([c for s in df[\"sub\"].values for c in s.lower()]))\n",
    "        char_enc.fit(chars)\n",
    "        data[\"lstm\"] = {\n",
    "            \"char_enc\": char_enc,\n",
    "        }\n",
    "    char_enc = data[\"lstm\"][\"char_enc\"]\n",
    "    \n",
    "    X_lstm = np.zeros((len(df), 50, len(char_enc.classes_)))\n",
    "    for idx, s in enumerate(df[\"sub\"].values):\n",
    "        s = s.lower()\n",
    "        while len(s) + 1 < 50:\n",
    "            s = \" \" + s + \" \"\n",
    "        if len(s) < 50:\n",
    "            s = s + \" \"\n",
    "            \n",
    "        chars = np.array(list(s.lower()))\n",
    "        enc = char_enc.transform(chars)\n",
    "        for jdx, x in enumerate(enc):\n",
    "            X_lstm[idx][jdx][x] = 1\n",
    "            \n",
    "    return X_lstm\n",
    "        \n",
    "X_lstm = get_lstm_repr(train_df, DATA)\n",
    "print(X_lstm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "emb_i (InputLayer)              [(None, 600)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_i (InputLayer)             [(None, 50, 41)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "syn_i (InputLayer)              [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "emb_dropout (Dropout)           (None, 600)          0           emb_i[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bilstm (Bidirectional)          (None, 128)          54272       lstm_i[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 734)          0           syn_i[0][0]                      \n",
      "                                                                 emb_dropout[0][0]                \n",
      "                                                                 bilstm[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 300)          220500      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            301         dense_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 275,073\n",
      "Trainable params: 275,073\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 11201 samples, validate on 2801 samples\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11201/11201 [==============================] - 13s 1ms/sample - loss: 0.1459 - val_loss: 0.1190\n",
      "Epoch 2/1000\n",
      "11201/11201 [==============================] - 8s 738us/sample - loss: 0.1057 - val_loss: 0.0847\n",
      "Epoch 3/1000\n",
      "11201/11201 [==============================] - 9s 775us/sample - loss: 0.0903 - val_loss: 0.0814\n",
      "Epoch 4/1000\n",
      "11201/11201 [==============================] - 9s 760us/sample - loss: 0.0811 - val_loss: 0.0791\n",
      "Epoch 5/1000\n",
      "11201/11201 [==============================] - 9s 779us/sample - loss: 0.0768 - val_loss: 0.0801\n",
      "Epoch 6/1000\n",
      "11201/11201 [==============================] - 9s 759us/sample - loss: 0.0743 - val_loss: 0.0787\n",
      "Epoch 7/1000\n",
      "11201/11201 [==============================] - 8s 719us/sample - loss: 0.0728 - val_loss: 0.0737\n",
      "Epoch 8/1000\n",
      "11201/11201 [==============================] - 8s 719us/sample - loss: 0.0707 - val_loss: 0.0737\n",
      "Epoch 9/1000\n",
      "11201/11201 [==============================] - 8s 729us/sample - loss: 0.0703 - val_loss: 0.0729\n",
      "Epoch 10/1000\n",
      "11201/11201 [==============================] - 8s 736us/sample - loss: 0.0695 - val_loss: 0.0718\n",
      "Epoch 11/1000\n",
      "11201/11201 [==============================] - 8s 740us/sample - loss: 0.0691 - val_loss: 0.0709\n",
      "Epoch 12/1000\n",
      "11201/11201 [==============================] - 9s 815us/sample - loss: 0.0679 - val_loss: 0.0700\n",
      "Epoch 13/1000\n",
      "11201/11201 [==============================] - 9s 844us/sample - loss: 0.0679 - val_loss: 0.0749\n",
      "Epoch 14/1000\n",
      "11201/11201 [==============================] - 10s 899us/sample - loss: 0.0674 - val_loss: 0.0678\n",
      "Epoch 15/1000\n",
      "11201/11201 [==============================] - 10s 852us/sample - loss: 0.0672 - val_loss: 0.0722\n",
      "Epoch 16/1000\n",
      " 3200/11201 [=======>......................] - ETA: 5s - loss: 0.0648"
     ]
    }
   ],
   "source": [
    "model = get_model(X_syn.shape[1], X_emb.shape[1], X_lstm.shape[1:])\n",
    "optimizer = tfk.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=abs_loss, optimizer=optimizer)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "reduce_lr = tfk.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=np.sqrt(0.1),\n",
    "    patience=5, \n",
    "    min_lr=1e-5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    [X_syn, X_emb, X_lstm], y, \n",
    "    batch_size=32,\n",
    "    epochs=1000,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[reduce_lr],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = read_df('data/test.txt', COL_NAMES[:-3])\n",
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.hstack([\n",
    "    get_syn(test_df, DATA, testing=True), \n",
    "    get_emb(test_df, DATA, testing=True), \n",
    "    get_grams(test_df, DATA, testing=True),\n",
    "])\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test).ravel()\n",
    "predictions = np.clip(predictions, 0, 1)\n",
    "print(predictions.shape)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission.txt', 'w') as file:\n",
    "    lines = [\"id,label\"]\n",
    "    for idx, pred in zip(test_df[\"idx\"], predictions):\n",
    "        lines.append(f\"{idx},{pred:.1f}\")\n",
    "    file.write('\\n'.join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
